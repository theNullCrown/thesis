Modern computational neuroscience has embraced random graph-based models, which also form the basis for Leslie Valiant's Neuroidal model, to comprehend cognition. Memories are construed as induced subgraphs within these models, yet the issue of memory capacity, initially addressed by Leslie Valiant in 2005, remains unexplored in a general context. The defining factor of capacity in our work is the concept of interference, which has not been explored rigorously for positive, shared memory representations. In simple terms, excessive interference signals the model has reached capacity. Since the most recent work by Valiant, exploration of general capacity has been limited, but recent investigations have delved into the capacity of the Assembly calculus, an explicit derivative of the Neuroidal model. In this paper, we provide rigorous definitions for capacity and interference and present theoretical formulations for memory capacity within a finite set, where subsets represent memories. We propose that these results can be adapted to suit the Neuroidal model and, eventually, the Assembly calculus. Furthermore, we substantiate our claims by providing simulations that validate our theoretical results. Our study aims to contribute essential insights into the understanding of memory capacity in complex cognitive models, offering potential ideas for applications and extensions to contemporary models of cognition. 
